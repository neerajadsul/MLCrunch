{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c17119ab",
   "metadata": {},
   "source": [
    "## Debugging a learning algorithm\n",
    "**Data**\n",
    "- get more training examples --> Reduce High Variance (overfit), Does not help high bias.\n",
    "\n",
    "**Features**\n",
    "- try smaller set of features --> Reduce High Variance (when model overfits the training data)\n",
    "- get additional features --> Reduce High Bias (when model underfits the training data)\n",
    "- get polynomial or higher-order features --> Reduce High Bias\n",
    "\n",
    "**Regularization**\n",
    "- decrease $\\lambda$ --> reduce underfitting, reduce high bias\n",
    "- increase $\\lambda$ --> reduce overfitting, reduce high variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a2f7d",
   "metadata": {},
   "source": [
    "## Evaluating a Model\n",
    "- A 1D or 2D model can be plotted to visualize the fit\n",
    "- Multidimensional data difficult to visualize\n",
    "\n",
    "## Split data into train and test and check the error\n",
    "\n",
    "70% data into training set $(X^{m_{train}}, y^{m_{train}})$\n",
    "\n",
    "30% data into test set $(X^{m_{test}}, y^{m_{test}})$\n",
    "\n",
    "#### For Regression Problems\n",
    "Compute Test Error and Train Error, without the regularization.\n",
    "$ J_{train}(W,b) $ and $ J_{test}(W,b) $\n",
    "\n",
    "#### For Classification Problems\n",
    "\n",
    "Compute Test Error and Train Error, **without the regularization.**\n",
    "\n",
    "$ J_{train}(W,b) $ = fraction of training set that has been misclassified\n",
    "\n",
    "$ J_{test}(W,b) $ = fraction of test set that has been misclassified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a09eccd",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "Split data into train, cross validation and test set groups in the proportion 60%/20%/20%.\n",
    "\n",
    "60% data into training set $(X^{m_{train}}, y^{m_{train}})$\n",
    "\n",
    "20% data into dev-set / cross-validation set $(X^{m_{dev}}, y^{m_{dev}})$ or $(X^{m_{cv}}, y^{m_{cv}})$\n",
    "\n",
    "20% data into test set $(X^{m_{test}}, y^{m_{test}})$\n",
    "\n",
    "Calculate $ J_{train}(W,b) $, $ J_{dev}(W,b) $ and $ J_{test}(W,b) $ without the regularization.\n",
    "\n",
    "Use **Dev Error** for evaluating the models.\n",
    "\n",
    "Use **Test Error** for estimating generalization error.\n",
    "\n",
    "$[Normalize Data] \\rightarrow [Loop Model List] \\rightarrow [Train Model] \\rightarrow [Train Error]\\rightarrow [Dev/CV Error]$\n",
    "\n",
    "$[Choose Model with Low Dev Error and Train Error] \\rightarrow [Test/Generalization Error] $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be23cec",
   "metadata": {},
   "source": [
    "## Bias and Variance Diagnostics\n",
    "\n",
    "![Bias and Variance](figures/bias_variance_diagnostics.jpg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86def4f9",
   "metadata": {},
   "source": [
    "## Effect of $\\lambda$ Regularization on Bias, Variance\n",
    "![Regularization on Bias, Variance](figures/regularization_bias_variance.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774fe1fc",
   "metadata": {},
   "source": [
    "## Establish Baseline Level Performance\n",
    "\n",
    "#### What is a reasonable level of error is acceptable or comparable?\n",
    "1. Human Level performance\n",
    "2. Competing Algorithm performance\n",
    "3. Educated Guess\n",
    "4. Regulations or established criteria.\n",
    "\n",
    "![](figures/baseline_bias_variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e66176f",
   "metadata": {},
   "source": [
    "## Learning Curves\n",
    "\n",
    "![](figures/training_set_size_learning_curve.png)\n",
    "\n",
    "- If the algorithm has high bias, increasing training set size will not help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3ab7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3369b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parabola(x, a=1, h=1, k=1): \n",
    "    return a*(x-h)**2 + k\n",
    "\n",
    "x = np.linspace(1, 5, 100)\n",
    "y1 = 1.1 - np.exp(1-x)\n",
    "y2 = 1.2 + np.exp(1-x)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(x, y1, label=r'$J_{train}$')\n",
    "plt.plot(x, y2, label=r'$J_{Dev/CV}$')\n",
    "plt.plot([0, 5],[1.15, 1.15], label=r'$J_{Baseline}$')\n",
    "plt.xlabel(r'$m_{train}$, training set size')\n",
    "plt.legend()\n",
    "plt.title('Acceptable')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(x, y1, label=r'$J_{train}$')\n",
    "plt.plot(x, y2, label=r'$J_{Dev/CV}$')\n",
    "plt.plot([0, 5],[0.5, 0.5], label=r'$J_{Baseline}$')\n",
    "plt.xlabel(r'$m_{train}$, training set size')\n",
    "plt.legend()\n",
    "plt.title('High Bias')\n",
    "\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(x, y1, label=r'$J_{train}$')\n",
    "plt.plot(x, y2, label=r'$J_{Dev/CV}$')\n",
    "plt.plot([0, 5],[1.2, 1.2], label=r'$J_{Baseline}$')\n",
    "plt.xlabel(r'$m_{train}$, training set size')\n",
    "plt.legend()\n",
    "plt.title('High Variance')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9ce39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'Baseline':(10.6, 10.6, 10.6),\n",
    "    'J_Train': (10.9, 15.6, 16.2),\n",
    "    'J_Dev': (14.6, 15.8, 19.7),\n",
    "}\n",
    "x = np.array([2, 5, 8])\n",
    "width = 0.33\n",
    "multiplier = 0\n",
    "for key, val in dataset.items():\n",
    "    offset = width * multiplier\n",
    "    rects = plt.bar(x + offset, val, width, label=key)\n",
    "    plt.bar_label(rects, padding=3)\n",
    "    multiplier += 1    \n",
    "plt.legend()\n",
    "plt.ylim([8, 20])\n",
    "plt.xticks(x, ['High Variance', 'High Bias', 'Far for Baseline'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
