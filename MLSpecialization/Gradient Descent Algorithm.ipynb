{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa3fcebe",
   "metadata": {},
   "source": [
    "# Gradient Descent (GD)\n",
    "Minimization of any function\n",
    "\n",
    "1. Start with initial values of $w$ and $b$\n",
    "2. Choose learning rate $\\alpha$\n",
    "3. Calculate the cost function\n",
    "\n",
    "$\\frac{\\partial}{\\partial w} J(w,b) = \\frac{1}{m} \\sum_{i=1}^{m} [f_{w,b}(x^{(i)}) - y] x^{(i)}$\n",
    "\n",
    "$ \\frac{\\partial}{\\partial b} J(w,b)=  \\frac{1}{m} \\sum_{i=1}^{m} [f_{w,b}(x^{(i)}) - y]$\n",
    "\n",
    "4. **simulteneously** Update the values\n",
    "\n",
    "$ w_1 = w_0 - \\alpha \\frac{\\partial}{\\partial w} J(w,b) $\n",
    "\n",
    "$ b_1 = b_0 - \\alpha \\frac{\\partial}{\\partial b} J(w,b) $\n",
    "\n",
    "5. Stop when minimized\n",
    "\n",
    "\n",
    "### Choice of learning rate $\\alpha$\n",
    "- too small $\\rightarrow$ GD slow, long time to converge\n",
    "- too large $\\rightarrow$ GD will overshoot, may not converge, in fact may diverge\n",
    "- fixed is ok $\\rightarrow$ The derivative gets smaller close to minima therefore step size reduces\n",
    "\n",
    "\n",
    "#### Mean Squared Error is Convex function\n",
    "Therefore there is only one minima."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a49d8",
   "metadata": {},
   "source": [
    "### Batch Gradient Descent\n",
    "Each step of the GD uses all of the training examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c097c10",
   "metadata": {},
   "source": [
    "## Practical Tips for GD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ea70c5",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "If the feature values have differnt range of values, the contour plot of the cost function is compressed in one direction. This slows down GD. If we scale the features so that their values are comparable then cost function is nice wide and symmetrical. This allows GD to converge faster as it can find direct path to optimum.\n",
    "\n",
    "For example, house prices range from 50k to 500k while the number of floors and rooms range from 1 to 7. \n",
    "\n",
    "#### Mean Normalization \n",
    "- scales between [-1.0, 1.0]\n",
    "- subtract mean from each sample and divide by the range of the feature values\n",
    "\n",
    "$X_1norm = \\frac{X_1 - \\mu_{X_1}}{X_1max - X_1min}$\n",
    "\n",
    "#### Z-Score Normalization\n",
    "- scales between [-1.0, 1.0]\n",
    "- subtract mean from each sample and divide by standard deviation of the feature\n",
    "\n",
    "$X_1norm = \\frac{X_1 - \\mu_{X_1}}{\\sigma_{X_1}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51ebce2",
   "metadata": {},
   "source": [
    "### GD Convergence Check\n",
    "- Check **learning curve** : plot of cost function $J(W, b)$ plotted against number of iterations.\n",
    "- Cost should decrease after every iteration\n",
    "\n",
    "#### Automatic Convergence Test\n",
    "If the decrease in $J(W, b)$ is less than a predefined number $\\epsilon$ then declare convergence. E.g. $\\epsilon = 10^{-6}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9ec1aa",
   "metadata": {},
   "source": [
    "### Choosing Learning Rate\n",
    "- If learning curve is oscillating then $\\alpha$ is too large.\n",
    "- If learning curve keeps increasing then $\\alpha$ is too large.\n",
    "\n",
    "When $\\alpha$ is small enough, the cost decreases on every iteration.\n",
    "\n",
    "However, if learning rate is too small, GD will be very slow to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4671b82",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "Create a new feature using combining or transforming existing features.\n",
    "\n",
    "### Polynomial Regression\n",
    "\n",
    "$f_{\\vec{W}, b} = w_1 x_1 + w_2 x_2^2 + w_3 x_3^3 + b$\n",
    "\n",
    "$f_{\\vec{W}, b} = w_1 x_1 + w_2 \\sqrt{x_2} + b$\n",
    "\n",
    "* In polynomial regression, feature scaling becomes very important."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
