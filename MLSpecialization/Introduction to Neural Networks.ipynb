{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69bc207f",
   "metadata": {},
   "source": [
    "#### Growth of neural network(NN) based algorithms:\n",
    "- large amount of data avaialble due to digitalization of everything\n",
    "- computational power exponentially grew especially with GPU computing\n",
    "\n",
    "#### NN\n",
    "- NN has inputs $X$ and an input layer with input neurons or nodes.\n",
    "- NN may have many hidden layers with nodes.\n",
    "- Each node has activation $a$.\n",
    "- NN has an output layer.\n",
    "\n",
    "\n",
    "## Neural Network Layers\n",
    "\n",
    "\n",
    "### Notation for NN Layers\n",
    "\n",
    "$a_j^{[L]}$ : activation value of layer $L$, node $j$\n",
    "\n",
    "$g$ : activation function \n",
    "\n",
    "$W_j^{(L)}$ : weight of layer $L$ node $j$\n",
    "\n",
    "$b_j^{[L]}$ : bias of layer $L$, node $j$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$ a_j^{[L]} = g(W_j^{[L]} \\cdot a^{[L-1]} + b_j^{[L]}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9593a82",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90f75f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def label(xy, text):\n",
    "    y = xy[1] - 0.15  # shift y-value for label so that it's below the artist\n",
    "    plt.text(xy[0], y, text, ha=\"center\", family='sans-serif', size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe72b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlim((0,20))\n",
    "ax.set_ylim((0,10))\n",
    "\n",
    "\n",
    "L = 0 \n",
    "X = 'X'\n",
    "label((1.5,5), r'$\\vec{X} = a^{[0]}$')\n",
    "\n",
    "\n",
    "for n,(x,y) in enumerate([(4,8),(4,5),(4,2)]):\n",
    "    c = plt.Circle((x,y), 1.2, ec='black', fc='white')\n",
    "    label((x, y), fr'$w^{(1)}_{n}, b_{n}^{(1)}$')\n",
    "    ax.add_artist(c)\n",
    "    label((x+1.7, y+0.2), fr'$a_{n}^{(1)}$')\n",
    "\n",
    "\n",
    "for n,(x,y) in enumerate([(8,8),(8,5),(8,2)]):\n",
    "    c = plt.Circle((x,y), 1, ec='black', fc='white')\n",
    "    label((x, y), fr'$w^{(2)}_{n}, b_{n}^{(2)}$')\n",
    "    ax.add_artist(c)\n",
    "    label((x+1.5, y), fr'$a_{n}^{(2)}$')\n",
    "    \n",
    "for n,(x,y) in enumerate([(12,7),(12,4)]):\n",
    "    c = plt.Circle((x,y), 1, ec='black', fc='white')\n",
    "    label((x, y), fr'$w^{(3)}_{n}, b_{n}^{(3)}$')\n",
    "    ax.add_artist(c)\n",
    "    label((x+1.5, y), fr'$a_{n}^{(3)}$')    \n",
    "    \n",
    "c = plt.Circle((16,5), 1, ec='black', fc='white')\n",
    "ax.add_artist(c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493b804b",
   "metadata": {},
   "source": [
    "#### Tensors(TF) vs NumPy\n",
    "Tensorflow stores data as Tensors, NumPy stores as arrays.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3963ab",
   "metadata": {},
   "source": [
    "If a NN has $S_{in}$ units in a layer and $S_{out}$ units in the next layer,\n",
    "\n",
    "$W$ dimensions are $S_{in} \\times S_{out}$ \n",
    "\n",
    "$b$ will be a vector with $S_{out}$ elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f958b32",
   "metadata": {},
   "source": [
    "## Artificial Intelligence\n",
    "- artificial narrow intelligence (ANI)\n",
    "    - web search\n",
    "    - object detection\n",
    "- artificial general intelligence (AGI)\n",
    "\n",
    "### _one learning algorithm_ analysis\n",
    "- one function of brain processes inputs from another sensory input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c75e2c",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "### Sigmoid Activation\n",
    "\n",
    "$g(z) = \\frac{1}{1+\\exp^{-z}}$\n",
    "\n",
    "- classification problems, especially binary classification\n",
    "- output layer Sigmoid\n",
    "### Rectified Linear Unit (ReLU)\n",
    "$g(z) = max(0, z)$\n",
    "\n",
    "- regression with only 0 or positive values\n",
    "- gradient descent is faster because function is flat half of area\n",
    "- hidden layers ReLU\n",
    "\n",
    "### Linear Activation\n",
    "$g(z) = z$ ;as if there is no activation\n",
    "\n",
    "- Regression\n",
    "### Softmax Activation\n",
    "Multiclass classification\n",
    "- classify digits from 0 to 9.\n",
    "\n",
    "\n",
    "\n",
    "### *tahn* Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb8679f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
